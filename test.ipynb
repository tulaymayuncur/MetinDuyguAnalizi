{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import pretrained tokenizer and model from https://huggingface.co/maymuni/bert-base-turkish-cased-emotion-analysis?text=I+like+you.+I+love+you\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"maymuni/bert-base-turkish-cased-emotion-analysis\")\n",
    "bert = AutoModel.from_pretrained(\"maymuni/bert-base-turkish-cased-emotion-analysis\",return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      super(Arch, self).__init__()\n",
    "      self.bert = bert \n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      self.relu =  nn.ReLU()\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      self.fc3 = nn.Linear(512,9)\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "      \n",
    "    def forward(self, sent_id, mask):\n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc3(x)\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')\n",
    "\n",
    "# pass the pre-trained model to our define architecture\n",
    "model = Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model_Final_son.pt modeli yukle ve test et\n",
    "model.load_state_dict(torch.load('my_model_final.pt', map_location=torch.device('mps')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "#Define predict function\n",
    "def predict_emotion(text):\n",
    "    tokenized = tokenizer.encode_plus(\n",
    "        text,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "    input_ids = tokenized['input_ids']\n",
    "    attention_mask = tokenized['attention_mask']\n",
    "\n",
    "    seq = torch.tensor(input_ids)\n",
    "    mask = torch.tensor(attention_mask)\n",
    "    seq = seq.unsqueeze(0)\n",
    "    mask = mask.unsqueeze(0)\n",
    "    preds = model(seq.to(device), mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    preds = torch.tensor(preds)\n",
    "    probabilities = nn.functional.softmax(preds)\n",
    "\n",
    "    # Get the top 3 emotions by probability\n",
    "    top3_emotions = heapq.nlargest(3, enumerate(probabilities[0]), key=lambda x: x[1])\n",
    "\n",
    "    # Get the names and probabilities of the top 3 emotions\n",
    "    top3_emotion_names = ['kızgın', 'üzgün', 'korku', 'iğrenme', 'mutlu', 'aşk', 'merak', 'utanç', 'şaşkınlık']\n",
    "    top3_emotion_probabilities = {top3_emotion_names[index]: float(prob) for index, prob in top3_emotions}\n",
    "\n",
    "    return top3_emotion_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/var/folders/c3/dqbzx13n0p59hyktphf9rw540000gn/T/ipykernel_27678/1024367870.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probabilities = nn.functional.softmax(preds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'iğrenme': 0.9926135540008545,\n",
       " 'utanç': 0.004823864437639713,\n",
       " 'korku': 0.0008097006939351559}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion('içimde bir endişe var')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
